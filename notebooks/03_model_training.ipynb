{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_model_training.ipynb\n",
    "# Interactive model training with monitoring\n",
    "\n",
    "## CELL 1: Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_model' from 'model' (C:\\Users\\Administrator\\Downloads\\lung_cancer_detection\\notebooks\\../src\\model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22276\\1476961971.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLUNA16Dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_data_loaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiTaskLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_model_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_system_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'create_model' from 'model' (C:\\Users\\Administrator\\Downloads\\lung_cancer_detection\\notebooks\\../src\\model.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loader import LUNA16Dataset, create_data_loaders\n",
    "from preprocessing import create_augmentation\n",
    "from model import create_model, MultiTaskLoss\n",
    "from train import Trainer\n",
    "from utils import set_seed, get_device, print_model_summary, log_system_info\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "print(\"‚úì Random seed set to 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System and Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LUNG CANCER DETECTION - MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Log system info\n",
    "log_system_info()\n",
    "\n",
    "# Load configuration\n",
    "with open('../configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"\\nüìã Configuration:\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  ROI size: {config['preprocessing']['roi_size']}\")\n",
    "print(f\"  Mixed precision: {config['training']['mixed_precision']}\")\n",
    "\n",
    "# Get device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPARING DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create augmentation\n",
    "augmentation = create_augmentation(config)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LUNA16Dataset(\n",
    "    data_dir=config['data']['processed_dir'],\n",
    "    annotations_file=config['data']['annotations_file'],\n",
    "    roi_size=tuple(config['preprocessing']['roi_size']),\n",
    "    transform=augmentation,\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "val_dataset = LUNA16Dataset(\n",
    "    data_dir=config['data']['processed_dir'],\n",
    "    annotations_file=config['data']['annotations_file'],\n",
    "    roi_size=tuple(config['preprocessing']['roi_size']),\n",
    "    transform=None,\n",
    "    mode='val'\n",
    ")\n",
    "\n",
    "# Split datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_indices = np.arange(len(train_dataset))\n",
    "train_indices, val_indices = train_test_split(\n",
    "    all_indices, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset.samples = [train_dataset.samples[i] for i in train_indices]\n",
    "val_dataset.samples = [val_dataset.samples[i] for i in val_indices]\n",
    "\n",
    "print(f\"\\n‚úì Dataset split:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Split ratio: {len(train_dataset)/len(val_dataset):.1f}:1\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader = create_data_loaders(config, train_dataset, val_dataset)\n",
    "\n",
    "print(f\"\\n‚úì Data loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Samples per epoch: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Sample Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE BATCH INSPECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get a sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"\\nBatch contents:\")\n",
    "print(f\"  Images: {sample_batch['image'].shape} - {sample_batch['image'].dtype}\")\n",
    "print(f\"  Labels: {sample_batch['label'].shape} - {sample_batch['label'].dtype}\")\n",
    "print(f\"  Malignancy: {sample_batch['malignancy'].shape} - {sample_batch['malignancy'].dtype}\")\n",
    "print(f\"  BBox: {sample_batch['bbox'].shape} - {sample_batch['bbox'].dtype}\")\n",
    "\n",
    "print(f\"\\nValue ranges:\")\n",
    "print(f\"  Images: [{sample_batch['image'].min():.4f}, {sample_batch['image'].max():.4f}]\")\n",
    "print(f\"  Labels: {sample_batch['label'].unique().tolist()}\")\n",
    "print(f\"  Malignancy: [{sample_batch['malignancy'].min():.2f}, {sample_batch['malignancy'].max():.2f}]\")\n",
    "\n",
    "# Visualize batch\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "batch_size = min(4, sample_batch['image'].shape[0])\n",
    "\n",
    "for i in range(batch_size):\n",
    "    volume = sample_batch['image'][i, 0].numpy()\n",
    "    mid_slice = volume.shape[0] // 2\n",
    "    \n",
    "    # CT slice\n",
    "    axes[0, i].imshow(volume[mid_slice], cmap='gray')\n",
    "    axes[0, i].set_title(f'Sample {i+1}\\nLabel: {sample_batch[\"label\"][i].item()}', \n",
    "                        fontsize=11, fontweight='bold')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # 3 orthogonal views\n",
    "    axes[1, i].imshow(volume[:, volume.shape[1]//2, :], cmap='gray')\n",
    "    axes[1, i].set_title(f'Malignancy: {sample_batch[\"malignancy\"][i].item():.0f}', \n",
    "                        fontsize=11)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Training Batch Samples', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/training_batch_samples.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Batch visualization complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create model\n",
    "model = create_model(config)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print_model_summary(model)\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "with torch.no_grad():\n",
    "    sample_input = sample_batch['image'][:2].to(device)\n",
    "    output = model(sample_input)\n",
    "    \n",
    "    print(f\"‚úì Forward pass successful\")\n",
    "    print(f\"  Detection logits: {output['detection']['class_logits'].shape}\")\n",
    "    print(f\"  Detection bbox: {output['detection']['bbox'].shape}\")\n",
    "    print(f\"  Detection confidence: {output['detection']['confidence'].shape}\")\n",
    "    print(f\"  Malignancy score: {output['malignancy'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOSS FUNCTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "criterion = MultiTaskLoss(\n",
    "    detection_weight=1.0,\n",
    "    malignancy_weight=1.0,\n",
    "    bbox_weight=0.5\n",
    ")\n",
    "\n",
    "print(\"Multi-task loss initialized:\")\n",
    "print(f\"  Detection weight: 1.0\")\n",
    "print(f\"  Malignancy weight: 1.0\")\n",
    "print(f\"  BBox weight: 0.5\")\n",
    "\n",
    "# Test loss computation\n",
    "print(\"\\nTesting loss computation...\")\n",
    "with torch.no_grad():\n",
    "    sample_targets = {\n",
    "        'label': sample_batch['label'][:2].to(device),\n",
    "        'malignancy': sample_batch['malignancy'][:2].to(device),\n",
    "        'bbox': sample_batch['bbox'][:2].to(device)\n",
    "    }\n",
    "    \n",
    "    loss, loss_dict = criterion(output, sample_targets)\n",
    "    \n",
    "    print(f\"‚úì Loss computation successful\")\n",
    "    print(f\"  Total loss: {loss.item():.4f}\")\n",
    "    print(f\"  Detection loss: {loss_dict['detection_loss']:.4f}\")\n",
    "    print(f\"  BBox loss: {loss_dict['bbox_loss']:.4f}\")\n",
    "    print(f\"  Malignancy loss: {loss_dict['malignancy_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINER INITIALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    config=config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"‚úì Trainer initialized\")\n",
    "print(f\"  Optimizer: {type(trainer.optimizer).__name__}\")\n",
    "print(f\"  Scheduler: {type(trainer.scheduler).__name__}\")\n",
    "print(f\"  Mixed precision: {trainer.use_amp}\")\n",
    "print(f\"  Gradient clipping: {trainer.grad_clip}\")\n",
    "print(f\"  Early stopping patience: {trainer.early_stopping_patience}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop (Main Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training for {config['training']['num_epochs']} epochs\")\n",
    "print(f\"Press Ctrl+C to interrupt\\n\")\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    history = trainer.train()\n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö† Training interrupted by user\")\n",
    "    history = trainer.history\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    history = trainer.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING HISTORY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print best results\n",
    "print(f\"\\nüèÜ Best Results:\")\n",
    "print(f\"  Best validation loss: {trainer.best_val_loss:.4f}\")\n",
    "print(f\"  Achieved at epoch: {np.argmin(history['val_loss']) + 1}\")\n",
    "\n",
    "# Loss statistics\n",
    "print(f\"\\nüìä Loss Statistics:\")\n",
    "print(f\"  Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final val loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Min train loss: {min(history['train_loss']):.4f}\")\n",
    "print(f\"  Min val loss: {min(history['val_loss']):.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "train_val_gap = history['train_loss'][-1] - history['val_loss'][-1]\n",
    "if abs(train_val_gap) > 0.5:\n",
    "    print(f\"\\n‚ö† Warning: Large train-val gap ({train_val_gap:.4f}) - possible overfitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING VISUALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Overall loss\n",
    "axes[0, 0].plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train', marker='o')\n",
    "axes[0, 0].plot(epochs, history['val_loss'], 'r-', linewidth=2, label='Validation', marker='s')\n",
    "axes[0, 0].axhline(y=trainer.best_val_loss, color='g', linestyle='--', \n",
    "                   label=f'Best Val: {trainer.best_val_loss:.4f}')\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Detection loss\n",
    "det_train = [m['detection_loss'] for m in history['train_metrics']]\n",
    "det_val = [m['detection_loss'] for m in history['val_metrics']]\n",
    "axes[0, 1].plot(epochs, det_train, 'b-', linewidth=2, label='Train', marker='o')\n",
    "axes[0, 1].plot(epochs, det_val, 'r-', linewidth=2, label='Validation', marker='s')\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Detection Loss', fontsize=12)\n",
    "axes[0, 1].set_title('Detection Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# BBox loss\n",
    "bbox_train = [m['bbox_loss'] for m in history['train_metrics']]\n",
    "bbox_val = [m['bbox_loss'] for m in history['val_metrics']]\n",
    "axes[1, 0].plot(epochs, bbox_train, 'b-', linewidth=2, label='Train', marker='o')\n",
    "axes[1, 0].plot(epochs, bbox_val, 'r-', linewidth=2, label='Validation', marker='s')\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('BBox Loss', fontsize=12)\n",
    "axes[1, 0].set_title('Bounding Box Loss', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Malignancy loss\n",
    "mal_train = [m['malignancy_loss'] for m in history['train_metrics']]\n",
    "mal_val = [m['malignancy_loss'] for m in history['val_metrics']]\n",
    "axes[1, 1].plot(epochs, mal_train, 'b-', linewidth=2, label='Train', marker='o')\n",
    "axes[1, 1].plot(epochs, mal_val, 'r-', linewidth=2, label='Validation', marker='s')\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Malignancy Loss', fontsize=12)\n",
    "axes[1, 1].set_title('Malignancy Loss', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/training_curves_detailed.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Training curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOSS COMPONENT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final epoch loss breakdown\n",
    "final_train = history['train_metrics'][-1]\n",
    "final_val = history['val_metrics'][-1]\n",
    "\n",
    "print(\"\\nFinal Epoch Loss Components:\")\n",
    "print(\"\\nTrain:\")\n",
    "for key, value in final_train.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "for key, value in final_val.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Visualize loss components over time\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(epochs, det_val, label='Detection', linewidth=2, marker='o')\n",
    "ax.plot(epochs, bbox_val, label='BBox', linewidth=2, marker='s')\n",
    "ax.plot(epochs, mal_val, label='Malignancy', linewidth=2, marker='^')\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=13)\n",
    "ax.set_ylabel('Validation Loss', fontsize=13)\n",
    "ax.set_title('Loss Components Evolution (Validation)', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/loss_components.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LEARNING RATE SCHEDULE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract learning rates (if logged)\n",
    "lrs = []\n",
    "for epoch in range(len(history['train_loss'])):\n",
    "    # Reconstruct LR from cosine schedule\n",
    "    import math\n",
    "    lr = config['training']['learning_rate'] * 0.5 * (\n",
    "        1 + math.cos(math.pi * epoch / config['training']['num_epochs'])\n",
    "    )\n",
    "    lrs.append(lr)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(epochs, lrs, linewidth=2, color='purple', marker='o')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Learning Rate', fontsize=12)\n",
    "plt.title('Learning Rate Schedule (Cosine Annealing)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/learning_rate_schedule.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nLearning rate:\")\n",
    "print(f\"  Initial: {lrs[0]:.6f}\")\n",
    "print(f\"  Final: {lrs[-1]:.6f}\")\n",
    "print(f\"  Min: {min(lrs):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Training Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING TRAINING REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create comprehensive report\n",
    "report = {\n",
    "    'experiment_info': {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'config': config,\n",
    "        'device': str(device),\n",
    "        'total_epochs': len(history['train_loss'])\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'train_samples': len(train_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'train_batches': len(train_loader),\n",
    "        'val_batches': len(val_loader)\n",
    "    },\n",
    "    'model_info': {\n",
    "        'architecture': 'SwinTransformer3D',\n",
    "        'total_parameters': sum(p.numel() for p in model.parameters()),\n",
    "        'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    },\n",
    "    'training_results': {\n",
    "        'best_val_loss': float(trainer.best_val_loss),\n",
    "        'best_epoch': int(np.argmin(history['val_loss']) + 1),\n",
    "        'final_train_loss': float(history['train_loss'][-1]),\n",
    "        'final_val_loss': float(history['val_loss'][-1]),\n",
    "        'min_train_loss': float(min(history['train_loss'])),\n",
    "        'min_val_loss': float(min(history['val_loss']))\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'train': final_train,\n",
    "        'validation': final_val\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(config['logging']['checkpoint_dir'], 'training_report.json')\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"‚úì Training report saved to {report_path}\")\n",
    "\n",
    "# Print summary\n",
    "summary_text = f\"\"\"\n",
    "{'='*60}\n",
    "TRAINING SUMMARY\n",
    "{'='*60}\n",
    "\n",
    "üìÖ Date: {report['experiment_info']['timestamp']}\n",
    "‚è±Ô∏è Total Epochs: {report['experiment_info']['total_epochs']}\n",
    "\n",
    "üìä Dataset:\n",
    "  - Training samples: {report['dataset_info']['train_samples']}\n",
    "  - Validation samples: {report['dataset_info']['val_samples']}\n",
    "\n",
    "üèóÔ∏è Model:\n",
    "  - Architecture: {report['model_info']['architecture']}\n",
    "  - Total parameters: {report['model_info']['total_parameters']:,}\n",
    "  - Trainable parameters: {report['model_info']['trainable_parameters']:,}\n",
    "\n",
    "üéØ Best Results:\n",
    "  - Best validation loss: {report['training_results']['best_val_loss']:.4f}\n",
    "  - Achieved at epoch: {report['training_results']['best_epoch']}\n",
    "\n",
    "üìà Final Loss:\n",
    "  - Train: {report['training_results']['final_train_loss']:.4f}\n",
    "  - Validation: {report['training_results']['final_val_loss']:.4f}\n",
    "\n",
    "üíæ Saved Artifacts:\n",
    "  ‚úì Model checkpoint: {config['logging']['checkpoint_dir']}/best_model.pth\n",
    "  ‚úì Training history: {config['logging']['checkpoint_dir']}/training_history.json\n",
    "  ‚úì Training report: {report_path}\n",
    "  ‚úì Visualizations: ../results/\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "\n",
    "print(summary_text)\n",
    "\n",
    "# Save summary as text\n",
    "summary_path = '../results/training_summary.txt'\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(f\"‚úì Summary saved to {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoint Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL CHECKPOINTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checkpoint_dir = config['logging']['checkpoint_dir']\n",
    "\n",
    "# List all checkpoints\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')])\n",
    "    \n",
    "    print(f\"\\nSaved checkpoints ({len(checkpoints)}):\")\n",
    "    for ckpt in checkpoints:\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        print(f\"  ‚Ä¢ {ckpt} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    # Load best model info\n",
    "    best_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    if os.path.exists(best_path):\n",
    "        checkpoint = torch.load(best_path, map_location='cpu')\n",
    "        print(f\"\\nüèÜ Best Model:\")\n",
    "        print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"  Validation loss: {checkpoint['best_val_loss']:.4f}\")\n",
    "        print(f\"  File size: {os.path.getsize(best_path) / (1024 * 1024):.2f} MB\")\n",
    "else:\n",
    "    print(\"\\n‚ö† No checkpoint directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUICK MODEL TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "best_model_path = os.path.join(config['logging']['checkpoint_dir'], 'best_model.pth')\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"‚úì Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "    \n",
    "    # Test on a validation batch\n",
    "    val_batch = next(iter(val_loader))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images = val_batch['image'].to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get predictions\n",
    "        det_probs = torch.softmax(outputs['detection']['class_logits'], dim=1)[:, 1]\n",
    "        mal_probs = outputs['malignancy']\n",
    "        \n",
    "        print(f\"\\nPredictions on validation batch:\")\n",
    "        print(f\"  Batch size: {images.shape[0]}\")\n",
    "        print(f\"  Detection probabilities: {det_probs.cpu().numpy()}\")\n",
    "        print(f\"  Malignancy probabilities: {mal_probs.cpu().numpy().flatten()}\")\n",
    "        \n",
    "        # Compare with ground truth\n",
    "        print(f\"\\nGround truth:\")\n",
    "        print(f\"  Labels: {val_batch['label'].numpy()}\")\n",
    "        print(f\"  Malignancy: {val_batch['malignancy'].numpy()}\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    \n",
    "    batch_size = min(4, images.shape[0])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        volume = images[i, 0].cpu().numpy()\n",
    "        mid_slice = volume.shape[0] // 2\n",
    "        \n",
    "        det_prob = det_probs[i].item()\n",
    "        mal_prob = mal_probs[i].item()\n",
    "        true_label = val_batch['label'][i].item()\n",
    "        true_mal = val_batch['malignancy'][i].item()\n",
    "        \n",
    "        # Top row: images\n",
    "        axes[0, i].imshow(volume[mid_slice], cmap='gray')\n",
    "        axes[0, i].set_title(f'Sample {i+1}', fontsize=12, fontweight='bold')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Bottom row: predictions\n",
    "        pred_text = (\n",
    "            f\"Detection: {det_prob:.3f}\\n\"\n",
    "            f\"True: {true_label}\\n\"\n",
    "            f\"Malignancy: {mal_prob:.3f}\\n\"\n",
    "            f\"True: {true_mal:.0f}\"\n",
    "        )\n",
    "        axes[1, i].text(0.5, 0.5, pred_text, \n",
    "                       transform=axes[1, i].transAxes,\n",
    "                       fontsize=11, ha='center', va='center',\n",
    "                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Model Predictions on Validation Set', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/quick_model_test.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì Model test complete\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Best model checkpoint not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Completion Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "completion_summary = f\"\"\"\n",
    "üéâ Training successfully completed!\n",
    "\n",
    "üìÅ Generated Artifacts:\n",
    "  ‚úì Model checkpoints in {checkpoint_dir}\n",
    "  ‚úì Training curves and visualizations in ../results/\n",
    "  ‚úì Training history JSON\n",
    "  ‚úì Comprehensive training report\n",
    "\n",
    "üéØ Next Steps:\n",
    "  1. Run evaluation notebook (04_evaluation_visualization.ipynb)\n",
    "  2. Generate Grad-CAM explainability visualizations\n",
    "  3. Test model on new CT scans using inference.py\n",
    "  4. Fine-tune hyperparameters if needed\n",
    "\n",
    "üìä Key Metrics:\n",
    "  ‚Ä¢ Best validation loss: {trainer.best_val_loss:.4f}\n",
    "  ‚Ä¢ Training epochs: {len(history['train_loss'])}\n",
    "  ‚Ä¢ Model parameters: {sum(p.numel() for p in model.parameters()):,}\n",
    "\n",
    "üí° Tips:\n",
    "  - Check training curves for signs of overfitting\n",
    "  - Compare train/val losses for generalization\n",
    "  - Review loss components to identify bottlenecks\n",
    "  - Use the best model checkpoint for inference\n",
    "\"\"\"\n",
    "\n",
    "print(completion_summary)\n",
    "\n",
    "# Save completion summary\n",
    "with open('../results/training_completion_summary.txt', 'w') as f:\n",
    "    f.write(completion_summary)\n",
    "\n",
    "print(\"\\nüìÑ All summaries and reports saved!\")\n",
    "print(\"üöÄ Ready for evaluation and deployment!\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
